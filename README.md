<div align="center">
  <img src="./image/kafka_gov_logo.png" alt="Kafka Gov Logo" width="400"/>
  
  **ğŸ›¡ï¸ Kafka Governance Platform**
  
  [![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://python.org)
  [![FastAPI](https://img.shields.io/badge/FastAPI-0.117+-green.svg)](https://fastapi.tiangolo.com)
  [![Coverage](https://img.shields.io/badge/Coverage-85%25-brightgreen.svg)](https://github.com/limhaneul12/kafka-gov)
  [![License](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
  
  **"Without knowing who owns a topic and what it's used for, Kafka is just a message queue."**
  
  [ğŸš€ Quick Start](#-quick-start) â€¢ [âœ¨ Features](#-features) â€¢ [ğŸ“– Documentation](#-documentation)
</div>

--- 

## ğŸ’¡ Why Kafka-Gov?

### The Problem

Existing Kafka UI tools (Kafka-UI, Conduktor, AKHQ) lack critical metadata capabilities:

- **ğŸ¤” Who owns this topic?** No ownership tracking across hundreds of topics
- **ğŸ“ What is it for?** Topic names alone don't explain purpose
- **ğŸ“š Where's the docs?** Documentation scattered across wikis and READMs
- **ğŸ”„ Change history?** No audit trail for partition changes or config updates
- **âš ï¸ Policy violations?** Can't detect risky configs like `min.insync.replicas=1` in production
- **ğŸš€ Batch operations?** Manual one-by-one topic creation for new projects

### The Solution

Kafka-Gov transforms Kafka into a **governed enterprise platform**:

| Problem | Solution |
|---------|----------|
| ğŸ” Unknown ownership | Mandatory `owner`, `team`, `tags` metadata |
| ğŸ“– Missing documentation | Direct Wiki/Confluence URL linking |
| ğŸš« No policies | Environment-specific validation (naming, replication, ISR) |
| â±ï¸ No audit trail | Automatic logging (who, when, what, why) |
| ğŸŒ Manual operations | YAML-based batch create/update/delete |
| ğŸ”— Topic-Schema gap | Automatic correlation and impact analysis |

---

## âœ¨ Features

### ğŸ”Œ Multi-Cluster Connection Management


- **ë™ì  í´ëŸ¬ìŠ¤í„° ë“±ë¡**: ì—¬ëŸ¬ Kafka í´ëŸ¬ìŠ¤í„°ë¥¼ ëŸ°íƒ€ì„ì— ë“±ë¡/ì „í™˜
- **ì—°ê²° ì •ë³´ ì €ì¥**: Bootstrap servers, SASL/SSL ì¸ì¦, íƒ€ì„ì•„ì›ƒ ì„¤ì •
- **Schema Registry ì—°ë™**: í´ëŸ¬ìŠ¤í„°ë³„ Schema Registry URL ë° ì¸ì¦ ê´€ë¦¬
- **Object Storage ì—°ë™**: MinIO/S3 í˜¸í™˜ ìŠ¤í† ë¦¬ì§€ ì—°ê²° (ìŠ¤í‚¤ë§ˆ ì•„í‹°íŒ©íŠ¸ ì €ì¥)
- **Kafka Connect ê´€ë¦¬**: Connect REST API URL ë° ì¸ì¦ ì •ë³´ ê´€ë¦¬
- **ì—°ê²° í…ŒìŠ¤íŠ¸**: ë“±ë¡ ì „ ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦ (latency ì¸¡ì •)
- **ì•”í˜¸í™”**: ë¯¼ê°í•œ ì¸ì¦ ì •ë³´ëŠ” ì•”í˜¸í™”í•˜ì—¬ ì €ì¥

**ì§€ì›ë˜ëŠ” ë³´ì•ˆ í”„ë¡œí† ì½œ:**
- PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
- SASL ë©”ì»¤ë‹ˆì¦˜: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, GSSAPI, OAUTHBEARER

### ğŸ·ï¸ Rich Topic Metadata

- **Owner & Team**: Track who owns and maintains each topic
- **Documentation**: Direct links to Wiki/Confluence docs (required)
- **Tags**: Flexible classification (`pii`, `critical`, `deprecated`)
- **At-a-glance**: View partitions, replication, retention instantly
- **Single Topic Creation**: Quick form-based creation for individual topics

### ğŸš€ YAML-Based Batch Operations

**Create/update/delete dozens of topics at once:**

```yaml
# example/batch_topics.yml
kind: TopicBatch
env: prod
change_id: "2025-01-15_my-project"
items:
  - name: prod.orders.created
    action: create
    config:
      partitions: 12
      replication_factor: 3
      retention_ms: 604800000
      min_insync_replicas: 2
    metadata:
      owner: team-commerce
      doc: "https://wiki.company.com/orders"
      tags: ["orders", "critical"]
```

**Features:**
- ğŸ”„ **Dry-Run**: Preview changes before applying
- âš ï¸ **Policy Validation**: Auto-check naming, replication, ISR
- ğŸ¯ **Parallel Processing**: Transactional batch operations
- ğŸ“‹ **YAML Upload**: Instant dry-run via file upload

See [`example/batch_topics.yml`](./example/batch_topics.yml) for a full example.

### ğŸ“¦ Schema Registry Management

- **Auto-Registration**: Automatic Schema Registry registration
- **Compatibility Modes**: Set schema evolution rules (BACKWARD, FORWARD, FULL, NONE)
- **Team Tracking**: Associate schemas with owning teams
- **Artifact Storage**: Permanent storage in MinIO (S3-compatible)
- **Topic Linking**: Auto-map schemas to topics (e.g., `prod.orders.created-value`)
- **Impact Analysis**: View topics affected by schema changes

**Compatibility Modes:**
- **BACKWARD** (default): New schema can read old data
- **FORWARD**: Old schema can read new data
- **FULL**: Both backward and forward compatible
- **NONE**: No compatibility checks

### ğŸ”Œ Kafka Connect Management

- **ì»¤ë„¥í„° CRUD**: Source/Sink ì»¤ë„¥í„° ìƒì„±, ì¡°íšŒ, ìˆ˜ì •, ì‚­ì œ
- **ìƒíƒœ ì œì–´**: ì»¤ë„¥í„°/íƒœìŠ¤í¬ ì‹œì‘, ì¼ì‹œì •ì§€, ì¬ì‹œì‘
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì»¤ë„¥í„° ë° íƒœìŠ¤í¬ ìƒíƒœ ì‹¤ì‹œê°„ í™•ì¸ (RUNNING, PAUSED, FAILED)
- **í”ŒëŸ¬ê·¸ì¸ ê´€ë¦¬**: ì„¤ì¹˜ëœ ì»¤ë„¥í„° í”ŒëŸ¬ê·¸ì¸ ëª©ë¡ ì¡°íšŒ ë° ì„¤ì • ê²€ì¦
- **í† í”½ ì¶”ì **: ì»¤ë„¥í„°ê°€ ì‚¬ìš© ì¤‘ì¸ í† í”½ ìë™ ì¶”ì 
- **ë©”íƒ€ë°ì´í„° ì—°ë™**: ì»¤ë„¥í„°ì— íŒ€/íƒœê·¸ ì •ë³´ ì—°ê²° (ê±°ë²„ë„ŒìŠ¤)
- **REST API í”„ë¡ì‹œ**: Kafka Connect REST APIë¥¼ ì•ˆì „í•˜ê²Œ í”„ë¡ì‹œ ì²˜ë¦¬

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… ì»¤ë„¥í„° ëª©ë¡ ì¡°íšŒ (expand ì˜µì…˜ìœ¼ë¡œ ìƒíƒœ/ì„¤ì • í•¨ê»˜ ì¡°íšŒ ê°€ëŠ¥)
- âœ… ì»¤ë„¥í„° ìƒì„±/ìˆ˜ì •/ì‚­ì œ (ì„¤ì • ê²€ì¦ í¬í•¨)
- âœ… ì»¤ë„¥í„° ì œì–´: pause/resume/restart
- âœ… íƒœìŠ¤í¬ ê´€ë¦¬: ê°œë³„ íƒœìŠ¤í¬ ì¬ì‹œì‘, ìƒíƒœ ì¡°íšŒ
- âœ… í”ŒëŸ¬ê·¸ì¸ ëª©ë¡ ë° ì„¤ì • ê²€ì¦

### ğŸ›¡ï¸ Environment-Specific Policies

| Policy | DEV | STG | PROD |
|--------|-----|-----|------|
| `min.insync.replicas` | â‰¥ 1 | â‰¥ 2 | â‰¥ 2 âš ï¸ |
| `replication.factor` | â‰¥ 1 | â‰¥ 2 | â‰¥ 3 âš ï¸ |
| Naming | `{env}.*` | `{env}.*` | `{env}.*` âš ï¸ |
| `tmp` prefix | âœ… Allow | âš ï¸ Warn | ğŸš« Block |

**Violations block dry-run:**
```
âŒ [ERROR] prod.tmp.test: 'tmp' prefix forbidden in prod
âŒ [ERROR] prod.orders: min.insync.replicas must be >= 2 (current: 1)
```

### ğŸ“Š Complete Audit Trail

- **Who**: Actor and team
- **When**: UTC timestamp
- **What**: Before/after config snapshots
- **Why**: Change ID linking to deployment
- **Result**: Success/partial/failed with details
- **Schema Events**: Track schema uploads, compatibility changes, and deletions

---

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/limhaneul12/kafka-gov.git
cd kafka-gov

# Configure environment
cp .env.example .env
# Edit .env with your Kafka connection details

# Start all services
docker-compose up -d

# Access application
open http://localhost:8000
```

**Endpoints:**
- Web UI: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Health: http://localhost:8000/health

**Upload your first batch:**
```bash
curl -X POST "http://localhost:8000/api/v1/topics/batch/upload" \
  -F "file=@example/batch_topics.yml"
```

Result: Dry-run preview â†’ Review violations â†’ Click "Apply Changes"

---

## ğŸ“– Documentation

### Creating Topics

**Option 1: Single Topic (Quick Form)**

1. Click "Single Topic Creation" in Topics tab
2. Fill in the form:
   - Environment (DEV/STG/PROD)
   - Topic name (e.g., `prod.order.count`)
   - Partitions, Replication Factor, Min In-Sync Replicas
   - Owner (team name)
   - Documentation URL (required)
   - Tags (optional)
3. Click "Create"

**Option 2: Batch Operations (YAML)**

**1. Write YAML file** (`my-topics.yml`):
```yaml
kind: TopicBatch
env: prod
change_id: "2025-01-15_my-project"
items:
  - name: prod.events.user-signup
    action: create
    config:
      partitions: 6
      replication_factor: 3
      min_insync_replicas: 2
    metadata:
      owner: team-growth
      doc: "https://wiki.company.com/events"
      tags: ["events"]
```

**2. Upload via Web UI:**
- Topics tab â†’ Batch Operations â†’ Upload YAML
- Review dry-run results
- Apply changes

**3. Or use API:**
```bash
curl -X POST "http://localhost:8000/api/v1/topics/batch/upload" \
  -F "file=@my-topics.yml"
```

### Updating Topics

```yaml
- name: prod.events.user-signup
  action: alter  # change to 'alter'
  config:
    partitions: 12  # increase partitions
```

### Deleting Topics

```yaml
- name: prod.deprecated.old-topic
  action: delete
```

---

## ğŸ—ï¸ Architecture

Built on **Clean Architecture** principles with domain-driven design:

```
app/
â”œâ”€â”€ shared/          # Common infrastructure & domain events
â”œâ”€â”€ cluster/         # Multi-cluster connection management
â”œâ”€â”€ connect/         # Kafka Connect management domain
â”œâ”€â”€ topic/           # Topic management domain
â”œâ”€â”€ schema/          # Schema registry domain
â”œâ”€â”€ analysis/        # Analysis & correlation domain
â”œâ”€â”€ container.py     # Root DI container
â””â”€â”€ main.py          # FastAPI application
```

**Key Principles:**
- **Clean Architecture**: Domain â†’ Application â†’ Infrastructure â†’ Interface
- **Event-Driven**: Domain events for cross-context communication (topic-schema sync)
- **Type Safety**: Python 3.12+ with strict typing, Pydantic v2, and msgspec validation
- **DI Container**: Hierarchical dependency injection with `dependency-injector`
- **High Performance**: Async/await throughout with connection pooling and batch operations
- **Observability**: Structured JSON logging, detailed validation errors, and health checks
- **Data-Oriented**: Immutable domain models with msgspec (frozen structs)
- **Error Resilience**: Circuit breakers, retry policies, and graceful degradation

## ğŸ› ï¸ Tech Stack

| Category | Technology |
|----------|------------|
| **Framework** | FastAPI 0.117+, Pydantic v2 |
| **Domain Models** | msgspec (high-performance serialization) |
| **Database** | SQLAlchemy 2.0 (Async), MySQL 8.0+ |
| **Message Broker** | Apache Kafka, Confluent Platform |
| **Schema Registry** | Confluent Schema Registry (with compatibility modes) |
| **Storage** | MinIO (S3-compatible) for schema artifacts |
| **Dependency Injection** | dependency-injector (hierarchical containers) |
| **Event Bus** | In-memory async event bus |
| **Architecture** | Clean Architecture, DDD, Event-Driven, CQRS |
| **Testing** | pytest, pytest-asyncio, pytest-cov (85% coverage) |
| **Type Safety** | Python 3.12+ (native union types, pattern matching) |
| **Package Manager** | uv (ultra-fast dependency resolution) |
| **Main Libraries** | confluent-kafka, aiomysql, httpx, orjson, aiofiles |
| **Error Handling** | Centralized exception handlers with detailed validation errors |

---

## âš™ï¸ Configuration

Key environment variables (`.env`):

```bash
# Database (ì—°ê²° ì •ë³´ ì €ì¥ìš©)
DATABASE_URL=mysql+aiomysql://user:pass@localhost/kafka_gov

# Default Kafka Cluster (ìµœì´ˆ ë“±ë¡ìš© - ì„ íƒì‚¬í•­)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_SECURITY_PROTOCOL=PLAINTEXT

# Default Schema Registry (ìµœì´ˆ ë“±ë¡ìš© - ì„ íƒì‚¬í•­)
SCHEMA_REGISTRY_URL=http://localhost:8081

# Default Object Storage (ìµœì´ˆ ë“±ë¡ìš© - ì„ íƒì‚¬í•­)
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=kafka-gov

# Default Kafka Connect (ìµœì´ˆ ë“±ë¡ìš© - ì„ íƒì‚¬í•­)
KAFKA_CONNECT_URL=http://localhost:8083

# Encryption (ë¯¼ê°í•œ ì •ë³´ ì•”í˜¸í™”ìš©)
ENCRYPTION_KEY=<generate using generate_encryption_key.py>
```

See [`.env.example`](.env.example) for all options.

---

## ğŸ”Œ API Reference

**Cluster Management**
- `GET /api/v1/clusters` - ë“±ë¡ëœ í´ëŸ¬ìŠ¤í„° ëª©ë¡ ì¡°íšŒ
- `POST /api/v1/clusters` - í´ëŸ¬ìŠ¤í„° ë“±ë¡
- `PUT /api/v1/clusters/{cluster_id}` - í´ëŸ¬ìŠ¤í„° ì •ë³´ ìˆ˜ì •
- `DELETE /api/v1/clusters/{cluster_id}` - í´ëŸ¬ìŠ¤í„° ì‚­ì œ
- `POST /api/v1/clusters/{cluster_id}/test` - ì—°ê²° í…ŒìŠ¤íŠ¸
- `POST /api/v1/clusters/{cluster_id}/activate` - í´ëŸ¬ìŠ¤í„° í™œì„±í™”

**Kafka Connect**
- `GET /api/v1/connect/connectors` - ì»¤ë„¥í„° ëª©ë¡ ì¡°íšŒ
- `POST /api/v1/connect/connectors` - ì»¤ë„¥í„° ìƒì„±
- `GET /api/v1/connect/connectors/{name}` - ì»¤ë„¥í„° ìƒì„¸ ì¡°íšŒ
- `PUT /api/v1/connect/connectors/{name}/config` - ì»¤ë„¥í„° ì„¤ì • ìˆ˜ì •
- `DELETE /api/v1/connect/connectors/{name}` - ì»¤ë„¥í„° ì‚­ì œ
- `POST /api/v1/connect/connectors/{name}/restart` - ì»¤ë„¥í„° ì¬ì‹œì‘
- `PUT /api/v1/connect/connectors/{name}/pause` - ì»¤ë„¥í„° ì¼ì‹œì •ì§€
- `PUT /api/v1/connect/connectors/{name}/resume` - ì»¤ë„¥í„° ì¬ê°œ
- `GET /api/v1/connect/connectors/{name}/status` - ì»¤ë„¥í„° ìƒíƒœ ì¡°íšŒ
- `GET /api/v1/connect/connectors/{name}/tasks` - íƒœìŠ¤í¬ ëª©ë¡ ì¡°íšŒ
- `POST /api/v1/connect/connectors/{name}/tasks/{id}/restart` - íƒœìŠ¤í¬ ì¬ì‹œì‘
- `GET /api/v1/connect/plugins` - í”ŒëŸ¬ê·¸ì¸ ëª©ë¡ ì¡°íšŒ
- `PUT /api/v1/connect/plugins/{class}/validate` - ì„¤ì • ê²€ì¦

**Topics**
- `POST /api/v1/topics/batch/upload` - Upload YAML & dry-run
- `POST /api/v1/topics/batch/apply` - Apply changes
- `GET /api/v1/topics` - List topics
- `DELETE /api/v1/topics/bulk-delete` - Bulk delete

**Schemas**
- `POST /api/v1/schemas/upload` - Upload schema files (with compatibility mode)
- `POST /api/v1/schemas/sync` - Sync from Schema Registry
- `GET /api/v1/schemas` - List schemas (with owner/team info)
- `GET /api/v1/schemas/artifacts` - List schema artifacts
- `DELETE /api/v1/schemas/{subject}` - Delete schema by subject

**Analysis**
- `GET /api/v1/analysis/correlation/by-schema/{subject}` - Topics using schema
- `GET /api/v1/analysis/impact/schema/{subject}` - Impact analysis

**System**
- `GET /health` - Health check
- `GET /docs` - Swagger UI

See full API docs at http://localhost:8000/docs

---

## ğŸš€ Deployment

**Docker Compose (Recommended)**
```bash
docker-compose up -d
```

**Production**
```bash
docker build -t kafka-gov:latest .
docker run -d -p 8000:8000 --env-file .env.prod kafka-gov:latest
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork repository
2. Create feature branch: `git checkout -b feature/my-feature`
3. Write tests: `uv run pytest --cov=app`
4. Commit: `git commit -m 'feat: Add feature'`
5. Push and create Pull Request

**Standards**: Python 3.12+, 80%+ test coverage, Clean Architecture, Ruff linting

---

## ğŸ“„ License

MIT License - see [LICENSE](./LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - Async web framework
- [Confluent Kafka](https://www.confluent.io/) - Python client
- [SQLAlchemy](https://www.sqlalchemy.org/) - Async ORM
- [msgspec](https://jcristharif.com/msgspec/) - High-performance serialization
- [uv](https://github.com/astral-sh/uv) - Fast package manager

---

<div align="center">
  
**Make Kafka safer and more efficient** ğŸš€

Made with â¤ï¸ by developers, for developers

â­ **Star if you find this useful!** â­

</div>